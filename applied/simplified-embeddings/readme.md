Train a okay sized model on all the text data scored from [https://github.com/2xic-speedrun/latios](https://github.com/2xic-speedrun/latios)

Train something like word2vec, or whatever you think might work. You can be a bit playful, but remember the goal.

Goal is that you should be able to use the output of the model to run KNN on text and the embeddings should make sense.

Tried to see if you can find things like [sentiment neuron](https://openai.com/research/unsupervised-sentiment-neuron)
