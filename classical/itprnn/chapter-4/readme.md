## The Source Coding Theorem
In this chapter we will look at 
- Shannon information is a sensible way of measuring information
- Entropy of the ensemble is a sensible measure of the average information
  
The less probable a outcome is, the higher is the Shannon information content.

### Shannon information
- One nice things by it being logs is the additive feature of logs over multiplication.
- There is also the guessing game which I think was mentioned in the original paper by Shannon (how many yes / no question do you need to ask to know the answer)
  - "Improbable outcomes do convey more information than probable outcomes"
