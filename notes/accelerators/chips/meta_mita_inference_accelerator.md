[Re-imagining Our Infrastructure for the AI Age ](https://about.fb.com/news/2023/05/metas-infrastructure-for-ai/)

## [MTIA v1: Metaâ€™s first-generation AI inference accelerator](https://ai.facebook.com/blog/meta-training-inference-accelerator-AI-MTIA/)
[Hackernews](https://news.ycombinator.com/item?id=36000221)
- **inference accelerator** not for training accelerations.
- Custom chip to help with their computation

They also have a [supercluster](https://ai.facebook.com/blog/supercomputer-meta-research-supercluster-2023/) now.
- ~ 5 exaflops
- 500 petabytes+ of storage
- 2k computers with 8 gpus each
- 

### [Our next-generation Meta Training and Inference Accelerator](https://ai.meta.com/blog/next-generation-meta-training-inference-accelerator-AI-MTIA/)
[Hackernews](https://news.ycombinator.com/item?id=39991675)
- They use a `Triton-MTIA` compiler
- 3x performance over hte previous generation
- 
