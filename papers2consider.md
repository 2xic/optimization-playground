# 2 consider

## Sources
- [https://spinningup.openai.com/en/latest/spinningup/keypapers.html](https://spinningup.openai.com/en/latest/spinningup/keypapers.html)
- [https://lilianweng.github.io/](https://lilianweng.github.io/)


## Some I'm considering
### Computer vision
[Unsupervised Monocular Depth Estimation with Left-Right Consistency](https://openaccess.thecvf.com/content_cvpr_2017/papers/Godard_Unsupervised_Monocular_Depth_CVPR_2017_paper.pdf?utm_source=pocket_mylist)
[What You Get Is What You See: A Visual Markup Decompiler](https://arxiv.org/pdf/1609.04938v1.pdf)

### RL 
[Recurrent World Models Facilitate Policy Evolution](https://arxiv.org/pdf/1809.01999.pdf?utm_source=pocket_mylist)

## NLP 
[Large Language Models Can Self-Improve](https://arxiv.org/pdf/2210.11610.pdf)
[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1810.04805.pdf)

## NN architecture
[Decoupled Neural Interfaces using Synthetic Gradients](https://arxiv.org/pdf/1608.05343.pdf)
[ZerO Initialization: Initializing Neural Networks with only Zeros and Ones](https://openreview.net/pdf?id=1AxQpKmiTc)

## Classical - Trees
[XGBoost: A Scalable Tree Boosting System](https://arxiv.org/pdf/1603.02754.pdf)

## Recommendations
[Monolith: Real Time Recommendation System With Collisionless Embedding Table](https://arxiv.org/pdf/2209.07663.pdf)
