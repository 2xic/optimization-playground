# 2 consider

## Source for papers 2 consider
- [https://paperswithcode.com/](https://paperswithcode.com/)
- [https://spinningup.openai.com/en/latest/spinningup/keypapers.html](https://spinningup.openai.com/en/latest/spinningup/keypapers.html)
- [https://lilianweng.github.io/](https://lilianweng.github.io/)
- [https://www.vicarious.com/publications/](https://www.vicarious.com/publications/)
- [https://openai.com/publications/](https://openai.com/publications/)
- [https://distill.pub/](https://distill.pub/)
- [https://github.com/lucidrains](https://github.com/lucidrains)
- 
# Some I'm considering

## Self supervised 
:)

### Computer vision
[https://vcrs.wpengine.com/wp-content/uploads/2020/03/1611.02788.pdf](https://vcrs.wpengine.com/wp-content/uploads/2020/03/1611.02788.pdf)

### RL 
[Transformers are Sample Efficient World Models](https://arxiv.org/pdf/2209.00588.pdf)
[Flow Network based Generative Models for Non-Iterative Diverse Candidate Generation](https://arxiv.org/pdf/2106.04399.pdf)
[Solving rubicks cube with robotic hand](https://arxiv.org/pdf/1910.07113.pdf)

## NLP 
[Large Language Models Can Self-Improve](https://arxiv.org/pdf/2210.11610.pdf)
[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1810.04805.pdf)

## GAN
:)

## NN architecture
[https://arxiv.org/pdf/2012.14905.pdf](Meta Learning Backpropagation And Improving It)
[https://arxiv.org/pdf/2212.05153.pdf](Algorithmic progress in computer vision)

## Recommendations
:)
