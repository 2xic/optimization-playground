Trying to replicate some of the plots from [deep double descent: where bigger models and more data hurt](https://arxiv.org/pdf/1912.02292.pdf)

~~Currently the speed is 2 slow for 4K epochs :'(  need to investigate !~~ I tried various things, but looks like batch size increase was the [best approach](./notes.md) 

**TODO*: Train the models with the configs. Currently lambda has no available instances, it would be nice to have a 8GPU machine**
