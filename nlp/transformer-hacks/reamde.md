Meant to be transformer version of [gan-hacks](/gan/gan-hacks)

## Good resources
- [Converting a From-Scratch GPT Architecture to Llama 2](https://github.com/rasbt/LLMs-from-scratch/blob/main/ch05/07_gpt_to_llama/converting-gpt-to-llama2.ipynb?trk=public_post_comment-text)
- [LLAMA source code](https://github.com/meta-llama/llama/blob/main/llama/model.py)

## TODO
- [Transformers without Normalization](https://huggingface.co/papers/2503.10622)
- Benchmark [DeepSeek v3](https://github.com/deepseek-ai/DeepSeek-V3/blob/main/inference/model.py) layers also
