# 2 consider
Papers that I have saved, and should look at.

## Source for papers 2 consider
- [https://huggingface.co/papers](https://huggingface.co/papers)
- [https://paperswithcode.com/](https://paperswithcode.com/)
- [https://spinningup.openai.com/en/latest/spinningup/keypapers.html](https://spinningup.openai.com/en/latest/spinningup/keypapers.html)
- [https://lilianweng.github.io/](https://lilianweng.github.io/)
- [https://www.vicarious.com/publications/](https://www.vicarious.com/publications/)
- [https://openai.com/publications/](https://openai.com/publications/)
- [https://distill.pub/](https://distill.pub/)
- [https://github.com/lucidrains](https://github.com/lucidrains)

# Some I'm considering

###  PHDs / Masters
Reading research done by (famous) students can be nice, it's one way to read the ideas of these students. 

[Ilya Sutskever (PHD)](http://www.cs.utoronto.ca/~ilya/pubs/ilya_sutskever_phd_thesis.pdf)

[Ilya Sutskever (Master)](http://www.cs.utoronto.ca/~ilya/MS_thesis/ms_body.pdf)

[Karpathy (PHD)](https://cs.stanford.edu/people/karpathy/main.pdf)

[Wojciech Zaremba (PHD) - Learning Algorithms from Data](https://cs.nyu.edu/media/publications/zaremba_wojciech.pdf)

### LLMs
[Generative Agents: Interactive Simulacra of Human Behavior](https://arxiv.org/pdf/2304.03442.pdf)

[A Generalist Agent](https://arxiv.org/pdf/2205.06175.pdf)

[PaLM 2 Technical Report](https://ai.google/static/documents/palm2techreport.pdf)

[AI Agent Basics: Let’s Think Step By Step](https://www.jonstokes.com/p/ai-agent-basics-lets-think-step-by)

### Computer vision
[https://vcrs.wpengine.com/wp-content/uploads/2020/03/1611.02788.pdf](https://vcrs.wpengine.com/wp-content/uploads/2020/03/1611.02788.pdf)

[https://nerf-w.github.io/](https://nerf-w.github.io/)

[Learning to Zoom and Unzoom](https://arxiv.org/pdf/2303.15390.pdf)

[Vision Transformers with Mixed-Resolution Tokenization ](https://arxiv.org/abs/2304.00287)

[ImageBind: Holistic AI learning across six modalities](https://ai.facebook.com/blog/imagebind-six-modalities-binding-ai/)

[What does CLIP know about a red circle?](https://arxiv.org/pdf/2304.06712.pdf)

[An Inverse Scaling Law for CLIP Training](https://arxiv.org/abs/2305.07017)

### RL 
[Transformers are Sample Efficient World Models](https://arxiv.org/pdf/2209.00588.pdf)

[Flow Network based Generative Models for Non-Iterative Diverse Candidate Generation](https://arxiv.org/pdf/2106.04399.pdf)

[Scaling Goal-based Exploration via Pruning Proto-goals](https://arxiv.org/pdf/2302.04693.pdf)

[Mastering Diverse Domains through World Models](https://arxiv.org/pdf/2301.04104.pdf)

[Deep RL at Scale: Sorting Waste in Office Buildings with a Fleet of Mobile Manipulators](https://arxiv.org/pdf/2305.03270.pdf)

[RLHF: Reinforcement Learning from Human Feedback](https://huyenchip.com/2023/05/02/rlhf.html)

## NLP 
[MiniGPT-4](https://github.com/Vision-CAIR/MiniGPT-4)

[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1810.04805.pdf)

[Meet in the Middle: A New Pre-training Paradigm](https://arxiv.org/pdf/2303.07295.pdf)

[Reflexion: an autonomous agent with dynamic memory and self-reflection](https://arxiv.org/pdf/2303.11366.pdf)
[Reflecting on Reflexion](https://nanothoughts.substack.com/p/reflecting-on-reflexion?utm_source=pocket_saves)

[The Curious Case of Absolute Position Embeddings](https://arxiv.org/pdf/2210.12574.pdf)
[The Use Case for Relative Position Embeddings](https://ofir.io/The-Use-Case-for-Relative-Position-Embeddings/?utm_source=pocket_saves)

[AttentionViz: A Global View of Transformer Attention](https://arxiv.org/pdf/2305.03210.pdf)

[Language models can explain neurons in language models](https://openai.com/research/language-models-can-explain-neurons-in-language-models)


[The Internal State of an LLM Knows When its Lying](https://arxiv.org/abs/2304.13734)

## GAN
[Neural Networks with Recurrent Generative Feedback](https://arxiv.org/pdf/2007.09200.pdf)

[Adding Conditional Control to Text-to-Image Diffusion Models](https://arxiv.org/abs/2302.05543)
[Adding Conditional Control to Text-to-Image Diffusion Models(code)](https://github.com/lllyasviel/ControlNet)

[Fast Text-Conditional Discrete Denoising on Vector-Quantized Latent Spaces](https://arxiv.org/abs/2211.07292)

[DiffusionRig: Learning Personalized Priors for Facial Appearance Editing ](https://diffusionrig.github.io/?utm_source=pocket_saves)

## NN architecture
[Meta Learning Backpropagation And Improving It](https://arxiv.org/pdf/2012.14905.pdf)

[Iriguing properties of neural networks](https://arxiv.org/pdf/1312.6199.pdf)

[http://proceedings.mlr.press/v37/ioffe15.pdf](http://proceedings.mlr.press/v37/ioffe15.pdf)

[Going Deeper with Convolutions](https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf)

## Infrastructure
[Velox: Meta’s Unified Execution Engine](https://scontent.fosl3-2.fna.fbcdn.net/v/t39.8562-6/302757195_3033291893628871_4556621853780203235_n.pdf?_nc_cat=109&ccb=1-7&_nc_sid=ad8a9d&_nc_ohc=83s6lshWWAEAX8A3wdW&_nc_ht=scontent.fosl3-2.fna&oh=00_AfAq1jZlnHlM139fSBQvQ1mQmgT-cyGDgwMlP-GixFdobw&oe=64080F67)
[Velox introduction](https://engineering.fb.com/2022/08/31/open-source/velox/?utm_source=pocket_reader)

## Robotics
[Model Predictive Control](https://folk.ntnu.no/skoge/vgprosessregulering/papers-pensum/seborg-c20ModelPredictiveControl.pdf)

[Learning Fine-Grained Bimanual Manipulation with Low-Cost Hardware](https://tonyzhaozh.github.io/aloha/aloha.pdf)
https://tonyzhaozh.github.io/aloha/

## Others
[SPREADING VECTORS FOR SIMILARITY SEARCH](https://arxiv.org/pdf/1806.03198.pdf)

