*TODO*

Idea I have 
- Train CLIP model on the flickr dataset
- Take out the text encoder model, and put it inside a GAN.
- Gan takes text as input -> CLIP transforms it and is used as Z vector -> Gan should output corresponding image based on flickr dataset (you reverse the training).

I think this should just work, and would be nice to test out.

